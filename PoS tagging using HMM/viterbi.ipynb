{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "train_file = \"train_data.csv\"\n",
    "test_file = \"validation_data.csv\"\n",
    "\n",
    "train_data = pd.read_csv(train_file)\n",
    "test_data = pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import ast\n",
    "\n",
    "# Dictionary of tag vs count\n",
    "tag_dict = defaultdict(int)\n",
    "\n",
    "# Dictionary of {word, tag} vs count\n",
    "word_tag_dict = defaultdict(int)\n",
    "\n",
    "# Dictionary of {tag i, tag i + 1} vs count\n",
    "two_tag_dict = defaultdict(int)\n",
    "\n",
    "# Total sentence count\n",
    "sentence_count = 0\n",
    "\n",
    "# Dictionary of first word vs count\n",
    "first_word_dict = defaultdict(int)\n",
    "\n",
    "for index, row in train_data.iterrows():\n",
    "    sentence = ast.literal_eval(row.iloc[0])\n",
    "    sentence_count = sentence_count + 1\n",
    "\n",
    "    first_word_dict[(sentence[0][0], sentence[0][1])] = first_word_dict[(sentence[0][0], sentence[0][1])] + 1\n",
    "\n",
    "    prev_tag = None\n",
    "    for word, tag in sentence:\n",
    "        tag_dict[tag] = tag_dict[tag] + 1\n",
    "        word_tag_dict[(word, tag)] = word_tag_dict[(word, tag)] + 1\n",
    "\n",
    "        if prev_tag is not None:\n",
    "            two_tag_dict[(prev_tag, tag)] = two_tag_dict[(prev_tag, tag)] + 1\n",
    "        prev_tag = tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tag_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in word_tag_dict.items():\n",
    "    print(f\"Key = {key}, Value = {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in two_tag_dict.items():\n",
    "    print(f\"Key = {key}, value = {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in first_word_dict.items():\n",
    "    print(f\"Key = {key}, value = {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emission probability\n",
    "emission_probability = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Transition probability\n",
    "transition_probability = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Initial probability\n",
    "initial_probability = defaultdict(int)\n",
    "\n",
    "for key, value in word_tag_dict.items():\n",
    "    emission_probability[key[0]][key[1]] = word_tag_dict[key]/tag_dict[key[1]]\n",
    "\n",
    "for key, value in two_tag_dict.items():\n",
    "    transition_probability[key[0]][key[1]] = two_tag_dict[key]/tag_dict[key[0]]\n",
    "\n",
    "for key, value in first_word_dict.items():\n",
    "    initial_probability[key[1]] = initial_probability[key[1]] + value/sentence_count\n",
    "\n",
    "# transition_probability[\"START\"] = initial_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in emission_probability.keys():\n",
    "    for tag, prob in emission_probability[word].items():\n",
    "        print(f\"Word = {word}, Tag = {tag}, Probability = {prob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag_1 in transition_probability.keys():\n",
    "    for tag_2, prob in transition_probability[tag_1].items():\n",
    "        print(f\"Tag 1 = {tag_1}, Tag 2 = {tag_2}, Probability = {prob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in initial_probability.items():\n",
    "    print(f\"Tag = {key}, Probability = {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Krish Attempt\n",
    "# import numpy as np\n",
    "\n",
    "# def viterbi_algorithm(\n",
    "#     sentence, unique_tags, initial_prob, transition_prob, emission_prob\n",
    "# )->list:\n",
    "#     n = len(sentence)\n",
    "#     m = len(unique_tags)\n",
    "#     tags_list = list(unique_tags)\n",
    "\n",
    "#     # Viterbi matrix\n",
    "#     viterbi = np.zeros((m, n))\n",
    "\n",
    "#     # Backpointer matrix\n",
    "#     backpointer = np.zeros((m, n), dtype=int)\n",
    "\n",
    "#     # Initialize first column\n",
    "#     for i, tag in enumerate(tags_list):\n",
    "#         viterbi[i, 0] = initial_prob.get(tag, 1e-6) * emission_prob.get(\n",
    "#             (tag, sentence[0]), 1e-6\n",
    "#         )\n",
    "\n",
    "#     # Recursion step\n",
    "#     for t in range(1, n):\n",
    "#         for j, curr_tag in enumerate(tags_list):\n",
    "#             max_prob, best_prev_tag = max(\n",
    "#                 [\n",
    "#                     (\n",
    "#                         viterbi[i, t - 1]\n",
    "#                         * transition_prob.get((prev_tag, curr_tag), 1e-6)\n",
    "#                         * emission_prob.get((curr_tag, sentence[t]), 1e-6),\n",
    "#                         i,\n",
    "#                     )\n",
    "#                     for i, prev_tag in enumerate(tags_list)\n",
    "#                 ]\n",
    "#             )\n",
    "#             viterbi[j, t] = max_prob\n",
    "#             backpointer[j, t] = best_prev_tag\n",
    "\n",
    "#     # Backtracking to retrieve the best sequence\n",
    "#     best_tags = []\n",
    "#     best_last_tag = np.argmax(viterbi[:, n - 1])\n",
    "#     best_tags.append(tags_list[best_last_tag])\n",
    "\n",
    "#     for t in range(n - 1, 0, -1):\n",
    "#         best_last_tag = backpointer[best_last_tag, t]\n",
    "#         best_tags.insert(0, tags_list[best_last_tag])\n",
    "\n",
    "#     return best_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valmik attempt - Optimized for efficiency using Python dictionaries\n",
    "from collections import defaultdict\n",
    "\n",
    "def viterbi_algorithm(sentence, unique_tags, initial_prob, transition_prob, emission_prob) -> list:\n",
    "    n = len(sentence)  # Number of words\n",
    "    tags_list = list(unique_tags)  # Convert set to list for indexing\n",
    "    viterbi = {tag: [0] * n for tag in tags_list}  # Using lists instead of defaultdict for speed\n",
    "    backpointer = {tag: [None] * n for tag in tags_list}  # Backpointer dictionary\n",
    "\n",
    "    # Initialize first column\n",
    "    for tag in tags_list:\n",
    "        viterbi[tag][0] = initial_prob.get(tag, 1e-6) * emission_prob.get((tag, sentence[0]), 1e-6)\n",
    "\n",
    "    # Recursion step using dictionaries\n",
    "    for t in range(1, n):\n",
    "        for curr_tag in tags_list:\n",
    "            prev_tag_probs = [\n",
    "                (viterbi[prev_tag][t - 1] * transition_prob.get((prev_tag, curr_tag), 1e-6) * emission_prob.get((curr_tag, sentence[t]), 1e-6), prev_tag)\n",
    "                for prev_tag in tags_list\n",
    "            ]\n",
    "            max_prob, best_prev_tag = max(prev_tag_probs, key=lambda x: x[0])\n",
    "            viterbi[curr_tag][t] = max_prob\n",
    "            backpointer[curr_tag][t] = best_prev_tag\n",
    "\n",
    "    # Backtracking to retrieve the best sequence\n",
    "    best_tags = []\n",
    "    best_last_tag = max(tags_list, key=lambda tag: viterbi[tag][-1])\n",
    "    best_tags.append(best_last_tag)\n",
    "\n",
    "    for t in range(n - 1, 0, -1):\n",
    "        best_last_tag = backpointer[best_last_tag][t]\n",
    "        best_tags.insert(0, best_last_tag)\n",
    "\n",
    "    return best_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict POS tags for the validation dataset\n",
    "predicted_tags = []\n",
    "actual_tags = []\n",
    "\n",
    "validation_sentences = []\n",
    "\n",
    "for index, row in test_data.iterrows():\n",
    "    validation_sentence = ast.literal_eval(row.iloc[0])\n",
    "    validation_sentences.append(validation_sentence)\n",
    "\n",
    "for sentence in validation_sentences:\n",
    "    words = [word for word, tag in sentence]\n",
    "    actual_tags.extend([tag for word, tag in sentence])\n",
    "\n",
    "    # Convert emission_probability to match expected format\n",
    "    emission_prob = {\n",
    "        (tag, word): emission_probability[word][tag]\n",
    "        for word in emission_probability\n",
    "        for tag in emission_probability[word]\n",
    "    }\n",
    "\n",
    "    predicted_tags.extend(\n",
    "        viterbi_algorithm(\n",
    "            words,\n",
    "            tag_dict.keys(),\n",
    "            initial_probability,\n",
    "            transition_probability,\n",
    "            emission_prob,  # Pass the reformatted emission probabilities\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(actual_tags, predicted_tags)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get unique tags from tag_dict\n",
    "unique_tags = list(tag_dict.keys())\n",
    "\n",
    "cm = confusion_matrix(actual_tags, predicted_tags, labels=list(unique_tags))\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    xticklabels=unique_tags,\n",
    "    yticklabels=unique_tags,\n",
    "    cmap=\"Blues\",\n",
    ")\n",
    "plt.xlabel(\"Predicted Tag\")\n",
    "plt.ylabel(\"Actual Tag\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
