{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(732, 15)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"sentimentdataset.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"Text\",\"Sentiment\"]]\n",
    "df[\"Sentiment\"] = df[\"Sentiment\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=sorted(df['Sentiment'].unique())\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Acceptance',\n",
       " 'Accomplishment',\n",
       " 'Admiration',\n",
       " 'Adoration',\n",
       " 'Adrenaline',\n",
       " 'Adventure',\n",
       " 'Affection',\n",
       " 'Amazement',\n",
       " 'Ambivalence',\n",
       " 'Amusement',\n",
       " 'Anger',\n",
       " 'Anticipation',\n",
       " 'Anxiety',\n",
       " 'Appreciation',\n",
       " 'Apprehensive',\n",
       " 'Arousal',\n",
       " 'ArtisticBurst',\n",
       " 'Awe',\n",
       " 'Bad',\n",
       " 'Betrayal',\n",
       " 'Bitter',\n",
       " 'Bitterness',\n",
       " 'Bittersweet',\n",
       " 'Blessed',\n",
       " 'Boredom',\n",
       " 'Breakthrough',\n",
       " 'Calmness',\n",
       " 'Captivation',\n",
       " 'Celebration',\n",
       " 'Celestial Wonder',\n",
       " 'Challenge',\n",
       " 'Charm',\n",
       " 'Colorful',\n",
       " 'Compassion',\n",
       " 'Compassionate',\n",
       " 'Confidence',\n",
       " 'Confident',\n",
       " 'Confusion',\n",
       " 'Connection',\n",
       " 'Contemplation',\n",
       " 'Contentment',\n",
       " 'Coziness',\n",
       " 'Creative Inspiration',\n",
       " 'Creativity',\n",
       " 'Culinary Adventure',\n",
       " 'CulinaryOdyssey',\n",
       " 'Curiosity',\n",
       " 'Darkness',\n",
       " 'Dazzle',\n",
       " 'Desolation',\n",
       " 'Despair',\n",
       " 'Desperation',\n",
       " 'Determination',\n",
       " 'Devastated',\n",
       " 'Disappointed',\n",
       " 'Disappointment',\n",
       " 'Disgust',\n",
       " 'Dismissive',\n",
       " 'DreamChaser',\n",
       " 'Ecstasy',\n",
       " 'Elation',\n",
       " 'Elegance',\n",
       " 'Embarrassed',\n",
       " 'Emotion',\n",
       " 'EmotionalStorm',\n",
       " 'Empathetic',\n",
       " 'Empowerment',\n",
       " 'Enchantment',\n",
       " 'Energy',\n",
       " 'Engagement',\n",
       " 'Enjoyment',\n",
       " 'Enthusiasm',\n",
       " 'Envious',\n",
       " 'Envisioning History',\n",
       " 'Envy',\n",
       " 'Euphoria',\n",
       " 'Excitement',\n",
       " 'Exhaustion',\n",
       " 'Exploration',\n",
       " 'Fear',\n",
       " 'Fearful',\n",
       " 'FestiveJoy',\n",
       " 'Free-spirited',\n",
       " 'Freedom',\n",
       " 'Friendship',\n",
       " 'Frustrated',\n",
       " 'Frustration',\n",
       " 'Fulfillment',\n",
       " 'Grandeur',\n",
       " 'Grateful',\n",
       " 'Gratitude',\n",
       " 'Grief',\n",
       " 'Happiness',\n",
       " 'Happy',\n",
       " 'Harmony',\n",
       " 'Hate',\n",
       " 'Heartache',\n",
       " 'Heartbreak',\n",
       " 'Heartwarming',\n",
       " 'Helplessness',\n",
       " 'Hope',\n",
       " 'Hopeful',\n",
       " 'Hypnotic',\n",
       " 'Iconic',\n",
       " 'Imagination',\n",
       " 'Immersion',\n",
       " 'Indifference',\n",
       " 'InnerJourney',\n",
       " 'Inspiration',\n",
       " 'Inspired',\n",
       " 'Intimidation',\n",
       " 'Intrigue',\n",
       " 'Isolation',\n",
       " 'Jealous',\n",
       " 'Jealousy',\n",
       " 'Journey',\n",
       " 'Joy',\n",
       " 'Joy in Baking',\n",
       " 'JoyfulReunion',\n",
       " 'Kind',\n",
       " 'Kindness',\n",
       " 'Loneliness',\n",
       " 'Loss',\n",
       " 'LostLove',\n",
       " 'Love',\n",
       " 'Marvel',\n",
       " 'Melancholy',\n",
       " 'Melodic',\n",
       " 'Mesmerizing',\n",
       " 'Mindfulness',\n",
       " 'Miscalculation',\n",
       " 'Mischievous',\n",
       " 'Motivation',\n",
       " \"Nature's Beauty\",\n",
       " 'Negative',\n",
       " 'Neutral',\n",
       " 'Nostalgia',\n",
       " 'Numbness',\n",
       " 'Obstacle',\n",
       " \"Ocean's Freedom\",\n",
       " 'Optimism',\n",
       " 'Overjoyed',\n",
       " 'Overwhelmed',\n",
       " 'Pensive',\n",
       " 'Playful',\n",
       " 'PlayfulJoy',\n",
       " 'Positive',\n",
       " 'Positivity',\n",
       " 'Pressure',\n",
       " 'Pride',\n",
       " 'Proud',\n",
       " 'Radiance',\n",
       " 'Reflection',\n",
       " 'Regret',\n",
       " 'Rejuvenation',\n",
       " 'Relief',\n",
       " 'Renewed Effort',\n",
       " 'Resentment',\n",
       " 'Resilience',\n",
       " 'Reverence',\n",
       " 'Romance',\n",
       " 'Ruins',\n",
       " 'Runway Creativity',\n",
       " 'Sad',\n",
       " 'Sadness',\n",
       " 'Satisfaction',\n",
       " 'Serenity',\n",
       " 'Shame',\n",
       " 'Solace',\n",
       " 'Solitude',\n",
       " 'Sorrow',\n",
       " 'Spark',\n",
       " 'Success',\n",
       " 'Suffering',\n",
       " 'Surprise',\n",
       " 'Suspense',\n",
       " 'Sympathy',\n",
       " 'Tenderness',\n",
       " 'Thrill',\n",
       " 'Thrilling Journey',\n",
       " 'Touched',\n",
       " 'Tranquility',\n",
       " 'Triumph',\n",
       " 'Vibrancy',\n",
       " 'Whimsy',\n",
       " 'Whispers of the Past',\n",
       " 'Winter Magic',\n",
       " 'Wonder',\n",
       " 'Wonderment',\n",
       " 'Yearning',\n",
       " 'Zest']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"SentimentEncoded\"] = label_encoder.fit_transform(df[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df[\"Text\"]\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# # Download stopwords if not already downloaded\n",
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download(\"punkt\")\n",
    "\n",
    "# stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# def remove_stopwords(text):\n",
    "#     words = word_tokenize(text)  # Tokenize text into words\n",
    "#     filtered_text = \" \".join([word for word in words if word.lower() not in stop_words])\n",
    "#     return filtered_text\n",
    "# X = X.apply(remove_stopwords)\n",
    "y = df[\"SentimentEncoded\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer(num_words=None, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert text to sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Padding sequences to ensure uniform input size\n",
    "MAX_LEN = 100\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding=\"post\")\n",
    "X_test_padded = pad_sequences(X_test_seq, maxlen=MAX_LEN, padding=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anurag/.local/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_7 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_8 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "\n",
    "# Define model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=256, input_length=MAX_LEN),  # Increased embedding size\n",
    "    Bidirectional(LSTM(units=128, return_sequences=True)),  # More LSTM units\n",
    "    Dropout(0.3),  # Regularization\n",
    "    Bidirectional(LSTM(units=64, return_sequences=False)),  \n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation=\"relu\"),  # Intermediate dense layer\n",
    "    Dense(191, activation=\"softmax\")  # Multi-class classification\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Fold 1...\n",
      "Epoch 1/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - accuracy: 0.0175 - loss: 5.2068 - val_accuracy: 0.0427 - val_loss: 5.0228\n",
      "Epoch 2/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 288ms/step - accuracy: 0.0623 - loss: 4.8283 - val_accuracy: 0.0427 - val_loss: 4.9452\n",
      "Epoch 3/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 296ms/step - accuracy: 0.0579 - loss: 4.7374 - val_accuracy: 0.0513 - val_loss: 4.9518\n",
      "Epoch 4/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 308ms/step - accuracy: 0.0995 - loss: 4.6120 - val_accuracy: 0.0427 - val_loss: 4.9926\n",
      "Epoch 5/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 303ms/step - accuracy: 0.1042 - loss: 4.4881 - val_accuracy: 0.0855 - val_loss: 4.8888\n",
      "Training on Fold 2...\n",
      "Epoch 1/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 311ms/step - accuracy: 0.1107 - loss: 4.5074 - val_accuracy: 0.1966 - val_loss: 4.1212\n",
      "Epoch 2/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 297ms/step - accuracy: 0.1065 - loss: 4.3578 - val_accuracy: 0.1880 - val_loss: 4.0675\n",
      "Epoch 3/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 185ms/step - accuracy: 0.1352 - loss: 4.1486 - val_accuracy: 0.1795 - val_loss: 4.0115\n",
      "Epoch 4/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 289ms/step - accuracy: 0.1715 - loss: 3.8077 - val_accuracy: 0.1880 - val_loss: 3.9932\n",
      "Epoch 5/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 306ms/step - accuracy: 0.1846 - loss: 3.6590 - val_accuracy: 0.1709 - val_loss: 3.9885\n",
      "Training on Fold 3...\n",
      "Epoch 1/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 298ms/step - accuracy: 0.1732 - loss: 3.5753 - val_accuracy: 0.2137 - val_loss: 3.3056\n",
      "Epoch 2/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 298ms/step - accuracy: 0.1990 - loss: 3.3525 - val_accuracy: 0.2991 - val_loss: 3.2371\n",
      "Epoch 3/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 302ms/step - accuracy: 0.2562 - loss: 3.1002 - val_accuracy: 0.2479 - val_loss: 3.2222\n",
      "Epoch 4/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 285ms/step - accuracy: 0.2801 - loss: 2.9584 - val_accuracy: 0.2393 - val_loss: 3.3832\n",
      "Epoch 5/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 307ms/step - accuracy: 0.3127 - loss: 2.7978 - val_accuracy: 0.2564 - val_loss: 3.2419\n",
      "Training on Fold 4...\n",
      "Epoch 1/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 182ms/step - accuracy: 0.2886 - loss: 2.8823 - val_accuracy: 0.3504 - val_loss: 2.4744\n",
      "Epoch 2/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 303ms/step - accuracy: 0.3631 - loss: 2.6968 - val_accuracy: 0.3419 - val_loss: 2.4844\n",
      "Epoch 3/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 295ms/step - accuracy: 0.4211 - loss: 2.3684 - val_accuracy: 0.3162 - val_loss: 2.5006\n",
      "Epoch 4/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 357ms/step - accuracy: 0.4240 - loss: 2.2294 - val_accuracy: 0.3419 - val_loss: 2.5455\n",
      "Epoch 5/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 305ms/step - accuracy: 0.4612 - loss: 2.1163 - val_accuracy: 0.3504 - val_loss: 2.5470\n",
      "Training on Fold 5...\n",
      "Epoch 1/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 312ms/step - accuracy: 0.4339 - loss: 2.1888 - val_accuracy: 0.4786 - val_loss: 2.0018\n",
      "Epoch 2/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 312ms/step - accuracy: 0.4858 - loss: 2.0491 - val_accuracy: 0.4957 - val_loss: 2.0268\n",
      "Epoch 3/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 313ms/step - accuracy: 0.5424 - loss: 1.7803 - val_accuracy: 0.4359 - val_loss: 2.1335\n",
      "Epoch 4/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 312ms/step - accuracy: 0.5212 - loss: 1.7770 - val_accuracy: 0.4615 - val_loss: 2.1421\n",
      "Epoch 5/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 313ms/step - accuracy: 0.5596 - loss: 1.5749 - val_accuracy: 0.4872 - val_loss: 2.1993\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_no = 1\n",
    "\n",
    "for train_index, val_index in kf.split(X_train_padded):\n",
    "    print(f\"Training on Fold {fold_no}...\")\n",
    "    \n",
    "    X_fold_train, X_fold_val = X_train_padded[train_index], X_train_padded[val_index]\n",
    "    y_fold_train, y_fold_val = np.array(y_train)[train_index], np.array(y_train)[val_index]\n",
    "\n",
    "    model.fit(X_fold_train, y_fold_train, validation_data=(X_fold_val, y_fold_val), epochs=5, batch_size=32)\n",
    "    \n",
    "    fold_no += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.1416 - loss: 7.6817\n",
      "Test Accuracy: 0.16\n"
     ]
    }
   ],
   "source": [
    "y_test = np.array(y_test)\n",
    "loss, acc = model.evaluate(X_test_padded, y_test)\n",
    "print(f\"Test Accuracy: {acc:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
